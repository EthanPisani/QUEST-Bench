model,beautiful_name,win_rate_character,win_rate_scene,win_rate_avg
character-AI,Character.AI,0.12467532467532468,0.16040955631399317,0.14254244049465892
claude-3-5-sonnet,Claude-3.5 Sonnet (2024-06-20),0.5667506297229219,0.6317460317460317,0.5992483307344768
claude-3-opus,Claude-3 Opus (2024-02-29),0.57,0.6167883211678832,0.5933941605839416
deepseek-v2,DeepSeek-V2 (2024-06-28),0.44191919191919193,0.3782991202346041,0.410109156076898
gemini-1.5-pro,Gemini 1.5 Pro,0.375,0.3367003367003367,0.35585016835016836
gpt-4-1106-preview,GPT-4-Turbo (1106 Preview),0.5793450881612091,0.5633802816901409,0.571362684925675
gpt-4o,GPT-4o (2024-05-13),0.5,0.5,0.5
higgs-llama-3-70b-240601,Higgs-Llama-3 70B (2024-06-01),0.47715736040609136,0.44200626959247646,0.4595818149992839
higgs-llama-3-70b-240629-v2,Higgs-Llama-3 70B V2 (2024-06-29),0.6825,0.7368421052631579,0.7096710526315789
llama-3-1-405b-instruct-fp8,Llama-3.1 405B Instruct (FP8),0.54,0.628125,0.5840625
llama-3-1-70b-instruct,Llama-3.1 70B Instruct,0.5325,0.6071428571428571,0.5698214285714285
llama-3-1-8b-instruct,Llama-3.1 8B Instruct,0.4,0.4361111111111111,0.41805555555555557
llama-3-70b-instruct,Llama-3 70B Instruct,0.4575,0.437125748502994,0.447312874251497
minimax-abab-6.5s,MiniMax abab6.5s,0.515,0.46774193548387094,0.49137096774193545
mistral-large-2402,Mistral Large (2024-02),0.3442211055276382,0.3670520231213873,0.35563656432451274
qwen2-72b-instruct,Qwen2 72B Instruct,0.4899497487437186,0.4119601328903654,0.450954940817042
yi-large,Yi Large (2024-05-13),0.5569620253164557,0.38509316770186336,0.4710275965091595
